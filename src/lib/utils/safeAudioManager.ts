import { toast } from "$lib/stores/toast"; // Toast ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”

/**
 * Safari í˜¸í™˜ì„±ì„ ìœ„í•œ ì˜¤ë””ì˜¤ ì‹±ê¸€í†¤ ë§¤ë‹ˆì €
 * - AudioContextì™€ AudioElementë¥¼ ì „ì—­ì—ì„œ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
 * - speak() í•¨ìˆ˜ í•˜ë‚˜ë¡œ ê¸°ì¡´ ë¡œì§ì„ ëŒ€ì²´í•©ë‹ˆë‹¤.
 */
export class SafeAudioManager {
    // --- Singleton Instances ---
    private static _context: AudioContext | null = null;
    private static _audio: HTMLAudioElement | null = null;
    private static _source: MediaElementAudioSourceNode | null = null;
    private static _analyser: AnalyserNode | null = null;
    private static _gain: GainNode | null = null;

    // --- State ---
    private static _isInit = false;

    /**
     * [í•„ìˆ˜] ì‚¬ìš©ì ì¸í„°ë™ì…˜(í´ë¦­/í„°ì¹˜) ì‹œì ì— í˜¸ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¹¨ì›ë‹ˆë‹¤.
     */
    public static init() {
        if (this._isInit && this._context?.state === "running") return;

        try {
            if (!this._context) {
                const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
                this._context = new AudioContextClass();

                // Audio Element ìƒì„± (ë”± 1ê°œ)
                this._audio = new Audio();
                this._audio.crossOrigin = "anonymous";
                this._audio.preload = "auto";

                // Gain Node (ë³¼ë¥¨ ì¡°ì ˆìš©)
                this._gain = this._context.createGain();
                this._gain.connect(this._context.destination);

                // Analyser Node (ë¦½ì‹±í¬ìš©)
                this._analyser = this._context.createAnalyser();
                this._analyser.fftSize = 256;
                this._analyser.minDecibels = -90;
                this._analyser.maxDecibels = -10;
                this._analyser.smoothingTimeConstant = 0.85;
                this._analyser.connect(this._gain);

                // Source Node ì—°ê²° (1íšŒë§Œ ìˆ˜í–‰í•´ì•¼ ì—ëŸ¬ ì—†ìŒ)
                this._source = this._context.createMediaElementSource(this._audio);
                this._source.connect(this._analyser);

                console.log("ğŸ”Š SafeAudioManager Initialized (Singleton)");
            }

            // Suspended ìƒíƒœë¼ë©´ Resume (Safari í•µì‹¬)
            if (this._context.state === "suspended") {
                this._context.resume().then(() => {
                    console.log("ğŸ”Š AudioContext Resumed!");
                });
            }
            this._isInit = true;
        } catch (e) {
            console.error("âŒ SafeAudioManager Init Failed:", e);
        }
    }

    /**
     * ê¸°ì¡´ MotionManager.speak í•¨ìˆ˜ë¥¼ ëŒ€ì²´í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
     * @param model Live2D ëª¨ë¸ ê°ì²´ (currentModel)
     * @param soundUrl ì˜¤ë””ì˜¤ íŒŒì¼ URL ë˜ëŠ” Base64
     * @param options ì˜µì…˜ (ë³¼ë¥¨, í‘œì • ë“±)
     */
    public static async speak(
        model: any,
        soundUrl: string,
        options: {
            volume?: number;
            expression?: string | number;
            resetExpression?: boolean;
            onFinish?: () => void;
            onError?: (e: Error) => void;
        } = {}
    ): Promise<boolean> {
        // 1. ì´ˆê¸°í™” (í˜¹ì‹œ ì•ˆë˜ì–´ìˆë‹¤ë©´ ì‹œë„)
        this.init();

        if (!this._context || !this._audio || !this._gain || !this._analyser) {
            console.error("âŒ Audio System not ready. Call init() on user click.");
            options.onError?.(new Error("Audio System not ready"));
            return false;
        }

        const {
            volume = 0.5,
            expression,
            resetExpression = true,
            onFinish,
            onError
        } = options;

        // 2. ì˜¤ë””ì˜¤ ì„¤ì •
        this._gain.gain.value = volume;
        this._audio.pause();
        this._audio.src = soundUrl;
        this._audio.currentTime = 0;

        // 3. Live2D ëª¨ë¸ì— ë¦½ì‹±í¬ ì •ë³´ ì£¼ì… (Dependency Injection)
        // ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìƒì„±í•˜ì§€ ì•Šë„ë¡, ìš°ë¦¬ê°€ ë§Œë“  ì‹±ê¸€í†¤ì„ ê½‚ì•„ì¤ë‹ˆë‹¤.
        if (model && model.internalModel && model.internalModel.motionManager) {
            const mgr = model.internalModel.motionManager;
            mgr.currentAudio = this._audio;
            mgr.currentContext = this._context;
            mgr.currentAnalyzer = this._analyser;
            // ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” SoundManager.volume ê°’ ë™ê¸°í™” (ì„ íƒì‚¬í•­)
            // (window as any).PIXI?.live2d?.SoundManager?.volume = volume;
        }

        // 4. í‘œì • ì„¤ì • (Expression)
        if (expression && model.expression) {
            if (resetExpression) {
                // ê¸°ì¡´ í‘œì • ë¦¬ì…‹ ë¡œì§ì´ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€ (ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¦„)
                // ë³´í†µ setExpression í˜¸ì¶œ ì‹œ ìë™ ì „í™˜ë¨
            }
            model.expression(expression);
        }

        // 5. ì¬ìƒ ì‹œì‘
        return new Promise((resolve) => {
            if (!this._audio) return resolve(false);

            // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (í•œë²ˆ ì“°ê³  ì œê±°í•˜ê¸° ìœ„í•´ í•¨ìˆ˜ë¡œ ì •ì˜)
            const handleEnded = () => {
                cleanup();
                if (resetExpression && model.internalModel?.motionManager?.expressionManager) {
                    model.internalModel.motionManager.expressionManager.resetExpression();
                }
                onFinish?.();
            };

            const handleError = (e: Event) => {
                cleanup();
                console.error("Audio Playback Error:", e);
                onError?.(new Error("Audio Playback Error"));
                resolve(false);
            };

            const cleanup = () => {
                this._audio?.removeEventListener("ended", handleEnded);
                this._audio?.removeEventListener("error", handleError);
            };

            this._audio.addEventListener("ended", handleEnded);
            this._audio.addEventListener("error", handleError);

            // Play
            this._audio.play()
                .then(() => {
                    resolve(true);
                })
                .catch((e) => {
                    console.warn("Autoplay blocked or interrupted:", e);
                    cleanup();
                    // ì‚¬ìš©ìê°€ ì•„ì§ í´ë¦­í•˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                    toast.error("í™”ë©´ì„ í„°ì¹˜í•´ì£¼ì„¸ìš” (Audio Blocked)");
                    resolve(false);
                });
        });
    }

    /**
     * ë¦½ì‹±í¬ ê³„ì‚° ë¡œì§ (ê¸°ì¡´ SoundManager.analyze ë³µì‚¬ë³¸)
     * í˜¹ì‹œ ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë½‘ì•„ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
     */
    public static getLipSyncValue(): number {
        if (!this._analyser) return 0;

        const pcmData = new Float32Array(this._analyser.fftSize);
        this._analyser.getFloatTimeDomainData(pcmData);

        let sumSquares = 0.0;
        for (const amplitude of pcmData) {
            sumSquares += amplitude * amplitude;
        }

        return parseFloat(Math.sqrt((sumSquares / pcmData.length) * 20).toFixed(1));
    }

    /**
     * í˜„ì¬ ì˜¤ë””ì˜¤ ì¦‰ì‹œ ì •ì§€
     */
    public static stop() {
        if (this._audio) {
            this._audio.pause();
            this._audio.currentTime = 0;
        }
    }
}